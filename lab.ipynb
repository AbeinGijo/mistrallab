{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c31267a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting mistralai\n",
      "  Downloading mistralai-1.12.3-py3-none-any.whl.metadata (33 kB)\n",
      "Collecting eval-type-backport>=0.2.0 (from mistralai)\n",
      "  Downloading eval_type_backport-0.3.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting httpx>=0.28.1 (from mistralai)\n",
      "  Using cached httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting invoke<3.0.0,>=2.2.0 (from mistralai)\n",
      "  Downloading invoke-2.2.1-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting opentelemetry-api<2.0.0,>=1.33.1 (from mistralai)\n",
      "  Downloading opentelemetry_api-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0 (from mistralai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting opentelemetry-sdk<2.0.0,>=1.33.1 (from mistralai)\n",
      "  Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl.metadata (1.5 kB)\n",
      "Collecting pydantic>=2.10.3 (from mistralai)\n",
      "  Downloading pydantic-2.12.5-py3-none-any.whl.metadata (90 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from mistralai) (2.9.0.post0)\n",
      "Collecting pyyaml<7.0.0,>=6.0.2 (from mistralai)\n",
      "  Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl.metadata (2.4 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from mistralai)\n",
      "  Downloading typing_inspection-0.4.2-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting anyio (from httpx>=0.28.1->mistralai)\n",
      "  Using cached anyio-4.12.1-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting certifi (from httpx>=0.28.1->mistralai)\n",
      "  Using cached certifi-2026.1.4-py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting httpcore==1.* (from httpx>=0.28.1->mistralai)\n",
      "  Using cached httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting idna (from httpx>=0.28.1->mistralai)\n",
      "  Using cached idna-3.11-py3-none-any.whl.metadata (8.4 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx>=0.28.1->mistralai)\n",
      "  Using cached h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting importlib-metadata<8.8.0,>=6.0 (from opentelemetry-api<2.0.0,>=1.33.1->mistralai)\n",
      "  Downloading importlib_metadata-8.7.1-py3-none-any.whl.metadata (4.7 kB)\n",
      "Collecting typing-extensions>=4.5.0 (from opentelemetry-api<2.0.0,>=1.33.1->mistralai)\n",
      "  Using cached typing_extensions-4.15.0-py3-none-any.whl.metadata (3.3 kB)\n",
      "Collecting googleapis-common-protos~=1.52 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Using cached googleapis_common_protos-1.72.0-py3-none-any.whl.metadata (9.4 kB)\n",
      "Collecting opentelemetry-exporter-otlp-proto-common==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl.metadata (1.8 kB)\n",
      "Collecting opentelemetry-proto==1.39.1 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Downloading opentelemetry_proto-1.39.1-py3-none-any.whl.metadata (2.3 kB)\n",
      "Collecting requests~=2.7 (from opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Using cached requests-2.32.5-py3-none-any.whl.metadata (4.9 kB)\n",
      "Collecting protobuf<7.0,>=5.0 (from opentelemetry-proto==1.39.1->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl.metadata (593 bytes)\n",
      "Collecting opentelemetry-semantic-conventions==0.60b1 (from opentelemetry-sdk<2.0.0,>=1.33.1->mistralai)\n",
      "  Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl.metadata (2.4 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic>=2.10.3->mistralai)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.41.5 (from pydantic>=2.10.3->mistralai)\n",
      "  Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl.metadata (7.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->mistralai) (1.17.0)\n",
      "Collecting zipp>=3.20 (from importlib-metadata<8.8.0,>=6.0->opentelemetry-api<2.0.0,>=1.33.1->mistralai)\n",
      "  Downloading zipp-3.23.0-py3-none-any.whl.metadata (3.6 kB)\n",
      "Collecting charset_normalizer<4,>=2 (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl.metadata (38 kB)\n",
      "Collecting urllib3<3,>=1.21.1 (from requests~=2.7->opentelemetry-exporter-otlp-proto-http<2.0.0,>=1.37.0->mistralai)\n",
      "  Using cached urllib3-2.6.3-py3-none-any.whl.metadata (6.9 kB)\n",
      "Downloading mistralai-1.12.3-py3-none-any.whl (502 kB)\n",
      "Downloading eval_type_backport-0.3.1-py3-none-any.whl (6.1 kB)\n",
      "Using cached httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Using cached httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading invoke-2.2.1-py3-none-any.whl (160 kB)\n",
      "Downloading opentelemetry_api-1.39.1-py3-none-any.whl (66 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_http-1.39.1-py3-none-any.whl (19 kB)\n",
      "Downloading opentelemetry_exporter_otlp_proto_common-1.39.1-py3-none-any.whl (18 kB)\n",
      "Downloading opentelemetry_proto-1.39.1-py3-none-any.whl (72 kB)\n",
      "Downloading opentelemetry_sdk-1.39.1-py3-none-any.whl (132 kB)\n",
      "Downloading opentelemetry_semantic_conventions-0.60b1-py3-none-any.whl (219 kB)\n",
      "Downloading pydantic-2.12.5-py3-none-any.whl (463 kB)\n",
      "Downloading pydantic_core-2.41.5-cp312-cp312-win_amd64.whl (2.0 MB)\n",
      "   ---------------------------------------- 0.0/2.0 MB ? eta -:--:--\n",
      "   ------------------------------------ --- 1.8/2.0 MB 11.2 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 2.0/2.0 MB 7.0 MB/s eta 0:00:00\n",
      "Using cached pyyaml-6.0.3-cp312-cp312-win_amd64.whl (154 kB)\n",
      "Downloading typing_inspection-0.4.2-py3-none-any.whl (14 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Using cached googleapis_common_protos-1.72.0-py3-none-any.whl (297 kB)\n",
      "Downloading importlib_metadata-8.7.1-py3-none-any.whl (27 kB)\n",
      "Using cached requests-2.32.5-py3-none-any.whl (64 kB)\n",
      "Using cached certifi-2026.1.4-py3-none-any.whl (152 kB)\n",
      "Using cached idna-3.11-py3-none-any.whl (71 kB)\n",
      "Using cached typing_extensions-4.15.0-py3-none-any.whl (44 kB)\n",
      "Using cached anyio-4.12.1-py3-none-any.whl (113 kB)\n",
      "Using cached charset_normalizer-3.4.4-cp312-cp312-win_amd64.whl (107 kB)\n",
      "Using cached h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Using cached protobuf-6.33.5-cp310-abi3-win_amd64.whl (437 kB)\n",
      "Using cached urllib3-2.6.3-py3-none-any.whl (131 kB)\n",
      "Downloading zipp-3.23.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: zipp, urllib3, typing-extensions, pyyaml, protobuf, invoke, idna, h11, eval-type-backport, charset_normalizer, certifi, annotated-types, typing-inspection, requests, pydantic-core, opentelemetry-proto, importlib-metadata, httpcore, googleapis-common-protos, anyio, pydantic, opentelemetry-exporter-otlp-proto-common, opentelemetry-api, httpx, opentelemetry-semantic-conventions, opentelemetry-sdk, opentelemetry-exporter-otlp-proto-http, mistralai\n",
      "Successfully installed annotated-types-0.7.0 anyio-4.12.1 certifi-2026.1.4 charset_normalizer-3.4.4 eval-type-backport-0.3.1 googleapis-common-protos-1.72.0 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 idna-3.11 importlib-metadata-8.7.1 invoke-2.2.1 mistralai-1.12.3 opentelemetry-api-1.39.1 opentelemetry-exporter-otlp-proto-common-1.39.1 opentelemetry-exporter-otlp-proto-http-1.39.1 opentelemetry-proto-1.39.1 opentelemetry-sdk-1.39.1 opentelemetry-semantic-conventions-0.60b1 protobuf-6.33.5 pydantic-2.12.5 pydantic-core-2.41.5 pyyaml-6.0.3 requests-2.32.5 typing-extensions-4.15.0 typing-inspection-0.4.2 urllib3-2.6.3 zipp-3.23.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install mistralai\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66fb571b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MISTRAL_API_KEY: NXyKdE5JFehmTjXn1RtYyVBOlMzPLGyB\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "os.environ[\"MISTRAL_API_KEY\"] = \"NXyKdE5JFehmTjXn1RtYyVBOlMzPLGyB\"\n",
    "print(f\"MISTRAL_API_KEY: {os.environ.get('MISTRAL_API_KEY')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "52cfb29a",
   "metadata": {},
   "outputs": [],
   "source": [
    "api_key = os.getenv(\"MISTRAL_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f7f07781",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from mistralai import Mistral, UserMessage\n",
    "def mistral(user_message, model=\"mistral-small-latest\", is_json=False):\n",
    "    model = \"mistral-large-latest\"\n",
    "    client = Mistral(api_key=api_key)\n",
    "    messages = [    UserMessage(content=user_message),    ]\n",
    "    chat_response = client.chat.complete(\n",
    "                                        model=model,\n",
    "                                        messages=messages,\n",
    "                                        )\n",
    "    return chat_response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e2c5c36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello! I‚Äôm an AI assistant here to help with a wide range of tasks. Here‚Äôs what I can do for you:\\n\\n### **General Assistance**\\n- Answer questions (facts, explanations, definitions, etc.)\\n- Provide summaries of articles, books, or topics\\n- Help with brainstorming ideas (writing, projects, business, etc.)\\n- Offer advice (career, study tips, productivity, etc.)\\n\\n### **Writing & Editing**\\n- Write or refine emails, essays, reports, or stories\\n- Generate creative content (poems, scripts, social media posts)\\n- Proofread and edit text for grammar, clarity, and style\\n- Help with resumes, cover letters, or LinkedIn profiles\\n\\n### **Learning & Research**\\n- Explain complex concepts (science, math, history, tech, etc.)\\n- Help with homework or study guides\\n- Find reliable sources or summarize research papers\\n- Translate text between languages\\n\\n### **Productivity & Organization**\\n- Create to-do lists, schedules, or study plans\\n- Suggest tools/apps for productivity, coding, design, etc.\\n- Help with project management (planning, timelines, etc.)\\n\\n### **Coding & Tech Help**\\n- Write, debug, or explain code (Python, JavaScript, SQL, etc.)\\n- Help with algorithms, data structures, or software design\\n- Explain tech concepts (AI, blockchain, cybersecurity, etc.)\\n\\n### **Creative & Fun Stuff**\\n- Generate jokes, riddles, or trivia\\n- Recommend books, movies, music, or games\\n- Help with world-building for stories or games\\n- Create memes or fun social media content\\n\\n### **Personal & Lifestyle**\\n- Suggest recipes, meal plans, or workout routines\\n- Help with travel planning (itineraries, tips, etc.)\\n- Offer mental health resources or mindfulness tips\\n\\n### **Business & Finance**\\n- Draft business plans or marketing strategies\\n- Explain financial concepts (investing, taxes, budgeting)\\n- Help with pitch decks or presentations\\n\\n### **Languages**\\n- Translate text (100+ languages)\\n- Help with language learning (vocabulary, grammar, practice)\\n\\n### **Limitations**\\n- I don‚Äôt have real-time access to the internet (my knowledge cutoff is **October 2023**).\\n- I can‚Äôt perform physical tasks or interact with external tools directly.\\n- I prioritize safety and avoid harmful, illegal, or unethical requests.\\n\\n**What would you like help with today?** üòä Just ask!'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral(\"hello, what can you do?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20834526",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "You are a bank customer service bot.\n",
    "Your task is to assess customer intent and categorize customer\n",
    "inquiry after <<<>>> into one of the following predefined categories:\n",
    "card arrival\n",
    "change pin\n",
    "exchange rate\n",
    "country support\n",
    "cancel transfer\n",
    "charge dispute\n",
    "If the text doesn't fit into any of the above categories,\n",
    "classify it as:\n",
    "customer service\n",
    "You will only respond with the predefined category.\n",
    "Do not provide explanations or notes.\n",
    "###\n",
    "Here are some examples:\n",
    "Inquiry: How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card.\n",
    "Category: card arrival\n",
    "Inquiry: I am planning an international trip to Paris and would like to inquire about the current exchange rates for Euros as well as any associated fees for the exchange.\n",
    "Category: exchange rate\n",
    "Inquiry: What countries are getting support? I will be traveling and living abroad for an extended period of time, specifically in France and Germany.\n",
    "Category: country support\n",
    "Inquiry: Can I get help starting my computer? I am having difficulty starting my computer, and would appreciate your expertise in helping me troubleshoot the computer.\n",
    "Category: customer service\n",
    "Inquiry: {inquiry}\n",
    "Category:\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e4244995",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "response = mistral(f\"Please correct the spelling and grammar of \\\n",
    "this prompt and return a text that is the same prompt,\\\n",
    "with the spelling and grammar fixed: {prompt}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "e92c170c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here‚Äôs your corrected prompt with proper spelling and grammar:\n",
      "\n",
      "---\n",
      "\n",
      "You are a bank customer service bot.\n",
      "Your task is to assess customer intent and categorize the customer inquiry after `<<<>>>` into one of the following predefined categories:\n",
      "- card arrival\n",
      "- change PIN\n",
      "- exchange rate\n",
      "- country support\n",
      "- cancel transfer\n",
      "- charge dispute\n",
      "\n",
      "If the text does not fit into any of the above categories, classify it as:\n",
      "- customer service\n",
      "\n",
      "You will only respond with the predefined category. Do not provide explanations or notes.\n",
      "\n",
      "###\n",
      "Here are some examples:\n",
      "**Inquiry:** How do I know if I will get my card, or if it is lost? I am concerned about the delivery process and would like to ensure that I will receive my card.\n",
      "**Category:** card arrival\n",
      "\n",
      "**Inquiry:** I am planning an international trip to Paris and would like to inquire about the current exchange rates for euros as well as any associated fees for the exchange.\n",
      "**Category:** exchange rate\n",
      "\n",
      "**Inquiry:** What countries are supported? I will be traveling and living abroad for an extended period of time, specifically in France and Germany.\n",
      "**Category:** country support\n",
      "\n",
      "**Inquiry:** Can I get help starting my computer? I am having difficulty starting it and would appreciate your expertise in troubleshooting.\n",
      "**Category:** customer service\n",
      "\n",
      "**Inquiry:** {inquiry}\n",
      "**Category:**\n",
      "\n",
      "---\n"
     ]
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "94fa6977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'country support'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "mistral(\n",
    "response.format(\n",
    "inquiry=\"I am inquiring about the availability of your cards in the EU\"\n",
    ")\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cd8916a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_notes = \"\"\"\n",
    "A 60-year-old male patient, Mr. Johnson, presented with symptoms\n",
    "of increased thirst, frequent urination, fatigue, and unexplained\n",
    "weight loss. Upon evaluation, he was diagnosed with diabetes,\n",
    "confirmed by elevated blood sugar levels. Mr. Johnson's weight\n",
    "is 210 lbs. He has been prescribed Metformin to be taken twice daily\n",
    "with meals. It was noted during the consultation that the patient is\n",
    "a current smoker.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bdc23c64",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "Extract information from the following medical notes:\n",
    "{medical_notes}\n",
    "Return json format with the following JSON schema:\n",
    "{{\n",
    "\"age\": {{\n",
    "\"type\": \"integer\"\n",
    "}},\n",
    "\"gender\": {{\n",
    "\"type\": \"string\",\n",
    "\"enum\": [\"male\", \"female\", \"other\"]\n",
    "}},\n",
    "\"diagnosis\": {{\n",
    "\"type\": \"string\",\n",
    "\"enum\": [\"migraine\", \"diabetes\", \"arthritis\", \"acne\"]\n",
    "}},\n",
    "\"weight\": {{\n",
    "\"type\": \"integer\"\n",
    "}},\n",
    "\"smoking\": {{\n",
    "\"type\": \"string\",\n",
    "\"enum\": [\"yes\", \"no\"]\n",
    "}}\n",
    "}}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3e4002a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here is the extracted information in the requested JSON format:\n",
      "\n",
      "```json\n",
      "{\n",
      "  \"age\": 60,\n",
      "  \"gender\": \"male\",\n",
      "  \"diagnosis\": \"diabetes\",\n",
      "  \"weight\": 210,\n",
      "  \"smoking\": \"yes\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "\n",
    "response = mistral(prompt, is_json=True)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cefa33f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "email = \"\"\"\n",
    "Dear mortgage lender,\n",
    "What's your 30-year fixed-rate APR, how is it compared to the 15-year\n",
    "fixed rate?\n",
    "Regards,\n",
    "Anna\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4822f994",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = f\"\"\"\n",
    "You are a mortgage lender customer service bot, and your task is to\n",
    "create personalized email responses to address customer questions.\n",
    "Answer the customer's inquiry using the provided facts below. Ensure\n",
    "that your response is clear, concise, and directly addresses the\n",
    "customer's question. Address the customer in a friendly and\n",
    "professional manner. Sign the email with \"Lender Customer Support.\"\n",
    "# Facts\n",
    "30-year fixed-rate: interest rate 6.403%, APR 6.484%\n",
    "20-year fixed-rate: interest rate 6.329%, APR 6.429%\n",
    "15-year fixed-rate: interest rate 5.705%, APR 5.848%\n",
    "10-year fixed-rate: interest rate 5.500%, APR 5.720%\n",
    "7-year ARM: interest rate 7.011%, APR 7.660%\n",
    "5-year ARM: interest rate 6.880%, APR 7.754%\n",
    "3-year ARM: interest rate 6.125%, APR 7.204%\n",
    "30-year fixed-rate FHA: interest rate 5.527%, APR 6.316%\n",
    "30-year fixed-rate VA: interest rate 5.684%, APR 6.062%\n",
    "# Email\n",
    "{email}\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0fda4005",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Subject:** Your 30-Year and 15-Year Fixed-Rate APR Details\n",
      "\n",
      "Dear Anna,\n",
      "\n",
      "Thank you for reaching out! Here are the details you requested:\n",
      "\n",
      "- **30-year fixed-rate APR:** 6.484%\n",
      "- **15-year fixed-rate APR:** 5.848%\n",
      "\n",
      "The 15-year fixed-rate option has a lower APR compared to the 30-year, which typically means lower overall interest costs over the life of the loan. However, the 15-year term will come with higher monthly payments since the loan is paid off in half the time.\n",
      "\n",
      "Would you like help comparing these options further or exploring other loan types? Let me know how I can assist!\n",
      "\n",
      "Best regards,\n",
      "**Lender Customer Support**\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "520282f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "newsletter= \"\"\"\n",
    "European AI champion Mistral AI unveiled new large language models and formed an alliance with Microsoft. \n",
    "\n",
    "What‚Äôs new: Mistral AI introduced two closed models, Mistral Large and Mistral Small (joining Mistral Medium, which debuted quietly late last year). Microsoft invested $16.3 million in the French startup, and it agreed to distribute Mistral Large on its Azure platform and let Mistral AI use Azure computing infrastructure. Mistral AI makes the new models available to try for free here and to use on its La Plateforme and via custom deployments.\n",
    "\n",
    "Model specs: The new models‚Äô parameter counts, architectures, and training methods are undisclosed. Like the earlier, open source Mistral 7B and Mixtral 8x7B, they can process 32,000 tokens of input context. \n",
    "\n",
    "Mistral Large achieved 81.2 percent on the MMLU benchmark, outperforming Anthropic‚Äôs Claude 2, Google‚Äôs Gemini Pro, and Meta‚Äôs Llama 2 70B, though falling short of GPT-4. Mistral Small, which is optimized for latency and cost, achieved 72.2 percent on MMLU.\n",
    "Both models are fluent in French, German, Spanish, and Italian. They‚Äôre trained for function calling and JSON-format output.\n",
    "Microsoft‚Äôs investment in Mistral AI is significant but tiny compared to its $13 billion stake in OpenAI and Google and Amazon‚Äôs investments in Anthropic, which amount to $2 billion and $4 billion respectively.\n",
    "Mistral AI and Microsoft will collaborate to train bespoke models for customers including European governments.\n",
    "Behind the news: Mistral AI was founded in early 2023 by engineers from Google and Meta. The French government has touted the company as a home-grown competitor to U.S.-based leaders like OpenAI. France‚Äôs representatives in the European Commission argued on Mistral‚Äôs behalf to loosen the European Union‚Äôs AI Act oversight on powerful AI models. \n",
    "\n",
    "Yes, but: Mistral AI‚Äôs partnership with Microsoft has divided European lawmakers and regulators. The European Commission, which already was investigating Microsoft‚Äôs agreement with OpenAI for potential breaches of antitrust law, plans to investigate the new partnership as well. Members of President Emmanuel Macron‚Äôs Renaissance party criticized the deal‚Äôs potential to give a U.S. company access to European users‚Äô data. However, other French lawmakers support the relationship.\n",
    "\n",
    "Why it matters: The partnership between Mistral AI and Microsoft gives the startup crucial processing power for training large models and greater access to potential customers around the world. It gives the tech giant greater access to the European market. And it gives Azure customers access to a high-performance model that‚Äôs tailored to Europe‚Äôs unique regulatory environment.\n",
    "\n",
    "We‚Äôre thinking: Mistral AI has made impressive progress in a short time, especially relative to the resources at its disposal as a startup. Its partnership with a leading hyperscaler is a sign of the tremendous processing and distribution power that remains concentrated in the large, U.S.-headquartered cloud companies.\n",
    "\"\"\"\n",
    "\n",
    "prompt = f\"\"\"\n",
    "You are a commentator. Your task is to write a report on a newsletter.\n",
    "When presented with the newsletter, come up with interesting questions to ask,\n",
    "and answer each question.\n",
    "Afterward, combine all the information and write a report in the markdown\n",
    "format.\n",
    "# Newsletter:\n",
    "{newsletter}\n",
    "# Instructions:\n",
    "## Summarize:\n",
    "In clear and concise language, summarize the key points and themes\n",
    "presented in the newsletter.\n",
    "## Interesting Questions:\n",
    "Generate three distinct and thought-provoking questions that can be\n",
    "asked about the content of the newsletter. For each question:\n",
    "- After \"Q: \", describe the problem\n",
    "- After \"A: \", provide a detailed explanation of the problem addressed\n",
    "in the question.\n",
    "- Enclose the ultimate answer in <>.\n",
    "## Write a analysis report\n",
    "Using the summary and the answers to the interesting questions,\n",
    "create a comprehensive report in Markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "daa04c7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# **Analysis Report: Mistral AI‚Äôs Strategic Alliance with Microsoft and Its Implications**\n",
      "\n",
      "## **Summary**\n",
      "Mistral AI, a rising European AI startup, has unveiled two new closed large language models (LLMs)‚Äî**Mistral Large** and **Mistral Small**‚Äîwhile forming a strategic partnership with **Microsoft**. Key developments include:\n",
      "- **New Models**: Mistral Large (81.2% on MMLU, outperforming Claude 2, Gemini Pro, and Llama 2 70B but trailing GPT-4) and Mistral Small (72.2% on MMLU, optimized for latency and cost).\n",
      "- **Microsoft Partnership**: A **$16.3M investment** (small compared to Microsoft‚Äôs $13B stake in OpenAI) and integration of Mistral Large on **Azure**, with joint efforts to train custom models for European governments.\n",
      "- **Multilingual & Functional Capabilities**: Both models support **French, German, Spanish, and Italian**, with function calling and JSON output.\n",
      "- **Regulatory & Political Tensions**: The deal has sparked **EU antitrust concerns** and divided French lawmakers over data sovereignty and U.S. tech dominance.\n",
      "- **Broader Implications**: The partnership strengthens Mistral‚Äôs access to compute and global markets while giving Microsoft a foothold in Europe‚Äôs AI ecosystem.\n",
      "\n",
      "---\n",
      "\n",
      "## **Interesting Questions**\n",
      "\n",
      "### **1. Q: How does Mistral AI‚Äôs performance compare to U.S.-based models, and what does this say about Europe‚Äôs AI competitiveness?**\n",
      "**A:**\n",
      "Mistral Large‚Äôs **81.2% on MMLU** places it ahead of **Claude 2 (78.5%), Gemini Pro (71.8%), and Llama 2 70B (68.9%)** but behind **GPT-4 (86.4%)**. This performance is remarkable given Mistral‚Äôs **startup status and limited resources** compared to tech giants like OpenAI, Google, and Meta.\n",
      "\n",
      "- **Europe‚Äôs AI Ambitions**: Mistral‚Äôs rapid progress suggests that Europe can compete in AI, but its reliance on **Microsoft‚Äôs Azure infrastructure** highlights a critical dependency on U.S. cloud providers.\n",
      "- **Resource Disparity**: While Mistral has achieved strong benchmarks, its **undisclosed parameter count and training methods** raise questions about whether it can sustain long-term competition without deeper investment.\n",
      "- **Regulatory Advantage**: Mistral‚Äôs models are **tailored for European compliance**, giving it an edge in government and enterprise adoption within the EU.\n",
      "\n",
      "**<Ultimate Answer: Mistral AI demonstrates that Europe can develop world-class LLMs, but its long-term competitiveness depends on reducing reliance on U.S. infrastructure and securing more funding.>**\n",
      "\n",
      "---\n",
      "\n",
      "### **2. Q: Why is Microsoft‚Äôs $16.3M investment in Mistral AI significant, and how does it fit into Microsoft‚Äôs broader AI strategy?**\n",
      "**A:**\n",
      "At first glance, **$16.3M is a small sum** compared to Microsoft‚Äôs **$13B investment in OpenAI** or Amazon‚Äôs **$4B in Anthropic**. However, the deal is strategically important for several reasons:\n",
      "\n",
      "- **European Market Access**: Microsoft gains a **local AI partner** to navigate EU regulations, avoiding the scrutiny faced by its OpenAI partnership.\n",
      "- **Azure Growth**: By hosting Mistral‚Äôs models, Microsoft **expands Azure‚Äôs AI offerings**, competing with Google Cloud and AWS.\n",
      "- **Diversification**: Unlike OpenAI, which is deeply integrated into Microsoft‚Äôs ecosystem, Mistral provides an **alternative LLM** that could appeal to European customers wary of U.S. dominance.\n",
      "- **Government & Enterprise Focus**: The collaboration on **custom models for European governments** positions Microsoft as a key player in **public-sector AI adoption**.\n",
      "\n",
      "**<Ultimate Answer: Microsoft‚Äôs investment in Mistral AI is a low-cost, high-reward move to strengthen its position in Europe, diversify its AI portfolio, and counter regulatory risks from its OpenAI partnership.>**\n",
      "\n",
      "---\n",
      "\n",
      "### **3. Q: What are the regulatory and political risks of the Mistral-Microsoft deal, and how might they impact the partnership?**\n",
      "**A:**\n",
      "The deal has **sparked controversy** on multiple fronts:\n",
      "\n",
      "- **EU Antitrust Concerns**: The **European Commission** is already investigating Microsoft‚Äôs OpenAI partnership for **potential antitrust violations**. The Mistral deal could face similar scrutiny, particularly if it **reinforces Microsoft‚Äôs dominance in cloud AI**.\n",
      "- **Data Sovereignty Issues**: French lawmakers from **President Macron‚Äôs party** have criticized the deal, fearing it could **expose European user data to U.S. jurisdiction** under laws like the **CLOUD Act**.\n",
      "- **AI Act Compliance**: Mistral previously **lobbied for lighter regulation** under the EU AI Act. Now, its partnership with a U.S. tech giant may **undermine its \"European champion\" narrative**, leading to stricter oversight.\n",
      "- **Geopolitical Tensions**: The deal reflects **Europe‚Äôs dilemma**‚Äîbalancing the need for **AI innovation** with **strategic autonomy** from U.S. tech.\n",
      "\n",
      "**Potential Outcomes:**\n",
      "- **Regulatory Delays**: The EU may impose **conditions** (e.g., data localization requirements) that increase costs for Mistral.\n",
      "- **Political Backlash**: If French or EU regulators perceive the deal as a **threat to sovereignty**, they could **block or restrict** aspects of the partnership.\n",
      "- **Alternative Partnerships**: Mistral may seek **European cloud providers** (e.g., OVHcloud, Deutsche Telekom) to mitigate regulatory risks.\n",
      "\n",
      "**<Ultimate Answer: The Mistral-Microsoft deal faces significant regulatory and political risks, particularly around antitrust, data sovereignty, and EU AI governance, which could force adjustments or even derail the partnership.>**\n",
      "\n",
      "---\n",
      "\n",
      "# **Comprehensive Analysis Report**\n",
      "\n",
      "```markdown\n",
      "# **Mistral AI‚Äôs Microsoft Alliance: A Strategic Move with High Stakes**\n",
      "\n",
      "## **1. Introduction**\n",
      "Mistral AI, a **Paris-based AI startup**, has rapidly emerged as Europe‚Äôs leading challenger to U.S.-dominated large language models (LLMs). Its latest announcement‚Äî**two new closed models (Mistral Large and Mistral Small) and a partnership with Microsoft**‚Äîmarks a pivotal moment in the global AI race. This report examines:\n",
      "- The **technical and strategic significance** of Mistral‚Äôs new models.\n",
      "- The **implications of Microsoft‚Äôs investment** for both companies.\n",
      "- The **regulatory and political risks** shaping the partnership‚Äôs future.\n",
      "\n",
      "---\n",
      "\n",
      "## **2. Mistral AI‚Äôs New Models: Performance and Positioning**\n",
      "\n",
      "### **2.1 Model Specifications and Benchmarks**\n",
      "Mistral AI introduced two new models, **Mistral Large** and **Mistral Small**, alongside the previously released **Mistral Medium**. Key details include:\n",
      "\n",
      "| Model          | MMLU Score | Key Features                          | Target Use Case                     |\n",
      "|----------------|------------|---------------------------------------|-------------------------------------|\n",
      "| **Mistral Large** | 81.2%      | 32K token context, multilingual, function calling | High-performance enterprise & government applications |\n",
      "| **Mistral Small** | 72.2%      | Optimized for latency & cost, JSON output | Cost-sensitive, real-time applications |\n",
      "| **Mistral Medium** | ~N/A       | Quietly released in 2023              | Mid-tier enterprise solutions       |\n",
      "\n",
      "**Performance Comparison:**\n",
      "- **Mistral Large outperforms** Anthropic‚Äôs Claude 2 (78.5%), Google‚Äôs Gemini Pro (71.8%), and Meta‚Äôs Llama 2 70B (68.9%).\n",
      "- **Still trails GPT-4 (86.4%)**, but closes the gap significantly for a startup.\n",
      "- **Multilingual advantage**: Strong support for **French, German, Spanish, and Italian**, addressing a key weakness of U.S.-centric models.\n",
      "\n",
      "### **2.2 Strategic Implications**\n",
      "- **Europe‚Äôs AI Ambitions**: Mistral‚Äôs rapid progress demonstrates that **Europe can compete in AI**, but its **undisclosed model size and training methods** raise questions about long-term scalability.\n",
      "- **Regulatory Tailoring**: The models are **designed for EU compliance**, making them attractive for **government and enterprise adoption** in Europe.\n",
      "- **Open vs. Closed Debate**: While Mistral initially gained fame with **open-source models (Mistral 7B, Mixtral 8x7B)**, its shift to **closed models** suggests a pivot toward **commercial viability**.\n",
      "\n",
      "---\n",
      "\n",
      "## **3. Microsoft‚Äôs $16.3M Investment: A Calculated Bet**\n",
      "\n",
      "### **3.1 Why Microsoft Invested in Mistral AI**\n",
      "Despite the **relatively small financial commitment**, Microsoft‚Äôs deal with Mistral is **strategically significant**:\n",
      "\n",
      "| **Microsoft‚Äôs Gain**               | **Mistral‚Äôs Gain**                     |\n",
      "|-------------------------------------|----------------------------------------|\n",
      "| **European Market Access**          | **Azure Compute & Distribution**       |\n",
      "| **Diversified AI Portfolio**        | **Global Customer Reach**              |\n",
      "| **Regulatory Hedge** (vs. OpenAI)   | **Funding for Scaling**                |\n",
      "| **Government & Enterprise Inroads** | **Custom Model Development**           |\n",
      "\n",
      "### **3.2 Comparison to Other AI Investments**\n",
      "Microsoft‚Äôs investment in Mistral is **modest** compared to its other AI bets:\n",
      "\n",
      "| **Company**       | **Investment** | **Microsoft‚Äôs Role**               |\n",
      "|-------------------|----------------|------------------------------------|\n",
      "| **OpenAI**        | $13B           | Exclusive cloud provider, deep integration |\n",
      "| **Mistral AI**    | $16.3M         | Azure distribution, compute access |\n",
      "| **Anthropic**     | (via Amazon)   | No direct investment               |\n",
      "\n",
      "**Key Takeaway**: Microsoft is **hedging its AI bets**‚Äîwhile OpenAI remains its flagship partner, Mistral provides a **European alternative** that could **mitigate regulatory risks**.\n",
      "\n",
      "---\n",
      "\n",
      "## **4. Regulatory and Political Risks: A Minefield for Mistral and Microsoft**\n",
      "\n",
      "### **4.1 EU Antitrust Concerns**\n",
      "- The **European Commission** is already investigating Microsoft‚Äôs **OpenAI partnership** for potential **antitrust violations**.\n",
      "- The Mistral deal could **trigger similar scrutiny**, particularly if it:\n",
      "  - **Reinforces Microsoft‚Äôs dominance** in cloud AI.\n",
      "  - **Limits competition** by tying Mistral‚Äôs models to Azure.\n",
      "\n",
      "### **4.2 Data Sovereignty and the CLOUD Act**\n",
      "- **French lawmakers** (including Macron‚Äôs Renaissance party) have **criticized the deal**, fearing:\n",
      "  - **U.S. access to European data** under the **CLOUD Act**.\n",
      "  - **Loss of digital sovereignty** to a U.S. tech giant.\n",
      "- **Potential Mitigations**:\n",
      "  - **Data localization requirements** (e.g., storing EU data in EU-based servers).\n",
      "  - **Alternative cloud partnerships** (e.g., OVHcloud, Deutsche Telekom).\n",
      "\n",
      "### **4.3 The EU AI Act and Mistral‚Äôs Lobbying**\n",
      "- Mistral previously **lobbied for lighter regulation** under the **EU AI Act**.\n",
      "- Now, its partnership with Microsoft may **undermine its \"European champion\" status**, leading to:\n",
      "  - **Stricter oversight** of its models.\n",
      "  - **Pressure to open-source** more of its technology.\n",
      "\n",
      "### **4.4 Geopolitical Tensions**\n",
      "- The deal highlights **Europe‚Äôs AI dilemma**:\n",
      "  - **Need for innovation** vs. **desire for strategic autonomy**.\n",
      "  - **Dependence on U.S. cloud providers** vs. **building European alternatives**.\n",
      "\n",
      "**Potential Outcomes:**\n",
      "‚úÖ **Best Case**: The deal proceeds with **minor regulatory adjustments**, strengthening Mistral‚Äôs position.\n",
      "‚ö†Ô∏è **Middle Ground**: **Data localization requirements** increase costs but allow the partnership to continue.\n",
      "‚ùå **Worst Case**: **EU antitrust action or political backlash** forces a restructuring or cancellation of the deal.\n",
      "\n",
      "---\n",
      "\n",
      "## **5. Broader Implications for the AI Industry**\n",
      "\n",
      "### **5.1 For Mistral AI**\n",
      "- **Pros**:\n",
      "  - **Access to Azure‚Äôs compute** for scaling.\n",
      "  - **Global distribution** via Microsoft‚Äôs enterprise channels.\n",
      "  - **Government contracts** in Europe.\n",
      "- **Cons**:\n",
      "  - **Regulatory risks** could delay or limit the partnership.\n",
      "  - **Loss of \"European purity\"** may alienate some customers.\n",
      "\n",
      "### **5.2 For Microsoft**\n",
      "- **Pros**:\n",
      "  - **European market expansion** without heavy investment.\n",
      "  - **Diversified AI portfolio** (reducing reliance on OpenAI).\n",
      "  - **Regulatory hedge** against OpenAI-related scrutiny.\n",
      "- **Cons**:\n",
      "  - **Potential antitrust action** in the EU.\n",
      "  - **Reputation risk** if the deal is seen as exploitative.\n",
      "\n",
      "### **5.3 For the AI Ecosystem**\n",
      "- **Concentration of Power**: The deal reinforces the **dominance of U.S. hyperscalers (Microsoft, Google, Amazon)** in AI infrastructure.\n",
      "- **Europe‚Äôs AI Strategy**: Mistral‚Äôs success (or failure) will shape **future EU funding and policy** for AI startups.\n",
      "- **Open vs. Closed Models**: Mistral‚Äôs shift to **closed models** reflects a broader industry trend toward **commercialization over open-source ideals**.\n",
      "\n",
      "---\n",
      "\n",
      "## **6. Conclusion: A High-Risk, High-Reward Gamble**\n",
      "\n",
      "The **Mistral-Microsoft partnership** is a **strategic masterstroke** with **significant upside** but **major regulatory and political risks**. Key takeaways:\n",
      "\n",
      "1. **Mistral AI is a serious contender**‚Äîits models compete with U.S. giants, but its long-term success depends on **scaling and funding**.\n",
      "2. **Microsoft‚Äôs investment is a low-cost, high-reward move** to **expand in Europe** while diversifying its AI portfolio.\n",
      "3. **Regulatory and political challenges** could **derail or reshape** the partnership, particularly around **antitrust, data sovereignty, and the EU AI Act**.\n",
      "4. **The deal underscores Europe‚Äôs AI dilemma**‚Äîbalancing **innovation with strategic autonomy** in a landscape dominated by U.S. tech.\n",
      "\n",
      "### **Final Outlook**\n",
      "- **Short-Term (2024)**: The partnership will **proceed with caution**, likely facing **EU scrutiny but no major disruptions**.\n",
      "- **Long-Term (2025+)**:\n",
      "  - If successful, Mistral could become a **key European AI player**, reducing reliance on U.S. models.\n",
      "  - If regulatory or political backlash intensifies, the deal may **unravel**, forcing Mistral to seek **alternative partners**.\n",
      "\n",
      "**Ultimately, this partnership is a microcosm of the broader AI race‚Äîwhere technical prowess, geopolitical maneuvering, and regulatory battles will determine the winners.**\n",
      "```\n",
      "\n",
      "---\n",
      "\n",
      "This report provides a **comprehensive, structured analysis** of Mistral AI‚Äôs Microsoft deal, covering **technical, strategic, regulatory, and geopolitical dimensions**.\n"
     ]
    }
   ],
   "source": [
    "response = mistral(prompt)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6ddaf5c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting streamlit\n",
      "  Using cached streamlit-1.54.0-py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting altair!=5.4.0,!=5.4.1,<7,>=4.0 (from streamlit)\n",
      "  Using cached altair-6.0.0-py3-none-any.whl.metadata (11 kB)\n",
      "Collecting blinker<2,>=1.5.0 (from streamlit)\n",
      "  Using cached blinker-1.9.0-py3-none-any.whl.metadata (1.6 kB)\n",
      "Collecting cachetools<7,>=5.5 (from streamlit)\n",
      "  Using cached cachetools-6.2.6-py3-none-any.whl.metadata (5.6 kB)\n",
      "Collecting click<9,>=7.0 (from streamlit)\n",
      "  Using cached click-8.3.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
      "  Using cached gitpython-3.1.46-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting numpy<3,>=1.23 (from streamlit)\n",
      "  Using cached numpy-2.4.2-cp312-cp312-win_amd64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: packaging>=20 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from streamlit) (26.0)\n",
      "Collecting pandas<3,>=1.4.0 (from streamlit)\n",
      "  Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl.metadata (19 kB)\n",
      "Collecting pillow<13,>=7.1.0 (from streamlit)\n",
      "  Using cached pillow-12.1.1-cp312-cp312-win_amd64.whl.metadata (9.0 kB)\n",
      "Collecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
      "  Using cached pydeck-0.9.1-py2.py3-none-any.whl.metadata (4.1 kB)\n",
      "Requirement already satisfied: protobuf<7,>=3.20 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from streamlit) (6.33.5)\n",
      "Collecting pyarrow>=7.0 (from streamlit)\n",
      "  Downloading pyarrow-23.0.1-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Requirement already satisfied: requests<3,>=2.27 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from streamlit) (2.32.5)\n",
      "Collecting tenacity<10,>=8.1.0 (from streamlit)\n",
      "  Using cached tenacity-9.1.4-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting toml<2,>=0.10.1 (from streamlit)\n",
      "  Using cached toml-0.10.2-py2.py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: tornado!=6.5.0,<7,>=6.0.3 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from streamlit) (6.5.4)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10.0 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from streamlit) (4.15.0)\n",
      "Collecting watchdog<7,>=2.1.5 (from streamlit)\n",
      "  Using cached watchdog-6.0.0-py3-none-win_amd64.whl.metadata (44 kB)\n",
      "Collecting jinja2 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached jinja2-3.1.6-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting jsonschema>=3.0 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached jsonschema-4.26.0-py3-none-any.whl.metadata (7.6 kB)\n",
      "Collecting narwhals>=1.27.1 (from altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached narwhals-2.16.0-py3-none-any.whl.metadata (14 kB)\n",
      "Requirement already satisfied: colorama in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from click<9,>=7.0->streamlit) (0.4.6)\n",
      "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached gitdb-4.0.12-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from pandas<3,>=1.4.0->streamlit) (2.9.0.post0)\n",
      "Collecting pytz>=2020.1 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached pytz-2025.2-py2.py3-none-any.whl.metadata (22 kB)\n",
      "Collecting tzdata>=2022.7 (from pandas<3,>=1.4.0->streamlit)\n",
      "  Using cached tzdata-2025.3-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: charset_normalizer<4,>=2 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.4.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (3.11)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2.6.3)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from requests<3,>=2.27->streamlit) (2026.1.4)\n",
      "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
      "  Using cached smmap-5.0.2-py3-none-any.whl.metadata (4.3 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl.metadata (2.8 kB)\n",
      "Collecting attrs>=22.2.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached attrs-25.4.0-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting jsonschema-specifications>=2023.03.6 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting referencing>=0.28.4 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached referencing-0.37.0-py3-none-any.whl.metadata (2.8 kB)\n",
      "Collecting rpds-py>=0.25.0 (from jsonschema>=3.0->altair!=5.4.0,!=5.4.1,<7,>=4.0->streamlit)\n",
      "  Using cached rpds_py-0.30.0-cp312-cp312-win_amd64.whl.metadata (4.2 kB)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\abein\\desktop\\mistrallab\\.venv\\lib\\site-packages (from python-dateutil>=2.8.2->pandas<3,>=1.4.0->streamlit) (1.17.0)\n",
      "Using cached streamlit-1.54.0-py3-none-any.whl (9.1 MB)\n",
      "Using cached altair-6.0.0-py3-none-any.whl (795 kB)\n",
      "Using cached blinker-1.9.0-py3-none-any.whl (8.5 kB)\n",
      "Using cached cachetools-6.2.6-py3-none-any.whl (11 kB)\n",
      "Using cached click-8.3.1-py3-none-any.whl (108 kB)\n",
      "Using cached gitpython-3.1.46-py3-none-any.whl (208 kB)\n",
      "Using cached numpy-2.4.2-cp312-cp312-win_amd64.whl (12.3 MB)\n",
      "Using cached pandas-2.3.3-cp312-cp312-win_amd64.whl (11.0 MB)\n",
      "Using cached pillow-12.1.1-cp312-cp312-win_amd64.whl (7.0 MB)\n",
      "Downloading pyarrow-23.0.1-cp312-cp312-win_amd64.whl (27.6 MB)\n",
      "   ---------------------------------------- 0.0/27.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/27.6 MB ? eta -:--:--\n",
      "   ---------------------------------------- 0.0/27.6 MB ? eta -:--:--\n",
      "    --------------------------------------- 0.5/27.6 MB 2.1 MB/s eta 0:00:13\n",
      "   - -------------------------------------- 1.0/27.6 MB 3.0 MB/s eta 0:00:09\n",
      "   -- ------------------------------------- 1.8/27.6 MB 2.6 MB/s eta 0:00:10\n",
      "   --- ------------------------------------ 2.4/27.6 MB 2.7 MB/s eta 0:00:10\n",
      "   ---- ----------------------------------- 3.1/27.6 MB 2.9 MB/s eta 0:00:09\n",
      "   ----- ---------------------------------- 3.9/27.6 MB 3.0 MB/s eta 0:00:08\n",
      "   ------ --------------------------------- 4.7/27.6 MB 3.1 MB/s eta 0:00:08\n",
      "   ------- -------------------------------- 5.5/27.6 MB 3.2 MB/s eta 0:00:07\n",
      "   --------- ------------------------------ 6.3/27.6 MB 3.2 MB/s eta 0:00:07\n",
      "   ---------- ----------------------------- 7.1/27.6 MB 3.3 MB/s eta 0:00:07\n",
      "   ----------- ---------------------------- 7.9/27.6 MB 3.3 MB/s eta 0:00:06\n",
      "   ------------ --------------------------- 8.7/27.6 MB 3.4 MB/s eta 0:00:06\n",
      "   ------------- -------------------------- 9.4/27.6 MB 3.4 MB/s eta 0:00:06\n",
      "   --------------- ------------------------ 10.5/27.6 MB 3.5 MB/s eta 0:00:05\n",
      "   ---------------- ----------------------- 11.3/27.6 MB 3.5 MB/s eta 0:00:05\n",
      "   ----------------- ---------------------- 12.1/27.6 MB 3.6 MB/s eta 0:00:05\n",
      "   ------------------ --------------------- 13.1/27.6 MB 3.6 MB/s eta 0:00:05\n",
      "   -------------------- ------------------- 13.9/27.6 MB 3.6 MB/s eta 0:00:04\n",
      "   --------------------- ------------------ 14.9/27.6 MB 3.7 MB/s eta 0:00:04\n",
      "   ---------------------- ----------------- 15.7/27.6 MB 3.7 MB/s eta 0:00:04\n",
      "   ------------------------ --------------- 16.8/27.6 MB 3.7 MB/s eta 0:00:03\n",
      "   ------------------------- -------------- 17.6/27.6 MB 3.8 MB/s eta 0:00:03\n",
      "   -------------------------- ------------- 18.4/27.6 MB 3.8 MB/s eta 0:00:03\n",
      "   --------------------------- ------------ 19.1/27.6 MB 3.8 MB/s eta 0:00:03\n",
      "   ----------------------------- ---------- 20.2/27.6 MB 3.8 MB/s eta 0:00:02\n",
      "   ----------------------------- ---------- 20.7/27.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.2/27.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------ --------- 21.2/27.6 MB 3.7 MB/s eta 0:00:02\n",
      "   ------------------------------- -------- 21.8/27.6 MB 3.6 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.3/27.6 MB 3.5 MB/s eta 0:00:02\n",
      "   -------------------------------- ------- 22.5/27.6 MB 3.5 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 22.8/27.6 MB 3.4 MB/s eta 0:00:02\n",
      "   --------------------------------- ------ 23.3/27.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 23.6/27.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ---------------------------------- ----- 24.1/27.6 MB 3.3 MB/s eta 0:00:02\n",
      "   ----------------------------------- ---- 24.4/27.6 MB 3.2 MB/s eta 0:00:02\n",
      "   ------------------------------------ --- 24.9/27.6 MB 3.2 MB/s eta 0:00:01\n",
      "   ------------------------------------ --- 25.2/27.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 25.7/27.6 MB 3.1 MB/s eta 0:00:01\n",
      "   ------------------------------------- -- 26.0/27.6 MB 3.1 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.5/27.6 MB 3.0 MB/s eta 0:00:01\n",
      "   -------------------------------------- - 26.7/27.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.3/27.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  27.5/27.6 MB 3.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 27.6/27.6 MB 2.9 MB/s eta 0:00:00\n",
      "Using cached pydeck-0.9.1-py2.py3-none-any.whl (6.9 MB)\n",
      "Using cached tenacity-9.1.4-py3-none-any.whl (28 kB)\n",
      "Using cached toml-0.10.2-py2.py3-none-any.whl (16 kB)\n",
      "Using cached watchdog-6.0.0-py3-none-win_amd64.whl (79 kB)\n",
      "Using cached gitdb-4.0.12-py3-none-any.whl (62 kB)\n",
      "Using cached jinja2-3.1.6-py3-none-any.whl (134 kB)\n",
      "Using cached jsonschema-4.26.0-py3-none-any.whl (90 kB)\n",
      "Using cached narwhals-2.16.0-py3-none-any.whl (443 kB)\n",
      "Using cached pytz-2025.2-py2.py3-none-any.whl (509 kB)\n",
      "Using cached tzdata-2025.3-py2.py3-none-any.whl (348 kB)\n",
      "Using cached attrs-25.4.0-py3-none-any.whl (67 kB)\n",
      "Using cached jsonschema_specifications-2025.9.1-py3-none-any.whl (18 kB)\n",
      "Using cached markupsafe-3.0.3-cp312-cp312-win_amd64.whl (15 kB)\n",
      "Using cached referencing-0.37.0-py3-none-any.whl (26 kB)\n",
      "Using cached rpds_py-0.30.0-cp312-cp312-win_amd64.whl (240 kB)\n",
      "Using cached smmap-5.0.2-py3-none-any.whl (24 kB)\n",
      "Installing collected packages: pytz, watchdog, tzdata, toml, tenacity, smmap, rpds-py, pyarrow, pillow, numpy, narwhals, MarkupSafe, click, cachetools, blinker, attrs, referencing, pandas, jinja2, gitdb, pydeck, jsonschema-specifications, gitpython, jsonschema, altair, streamlit\n",
      "Successfully installed MarkupSafe-3.0.3 altair-6.0.0 attrs-25.4.0 blinker-1.9.0 cachetools-6.2.6 click-8.3.1 gitdb-4.0.12 gitpython-3.1.46 jinja2-3.1.6 jsonschema-4.26.0 jsonschema-specifications-2025.9.1 narwhals-2.16.0 numpy-2.4.2 pandas-2.3.3 pillow-12.1.1 pyarrow-23.0.1 pydeck-0.9.1 pytz-2025.2 referencing-0.37.0 rpds-py-0.30.0 smmap-5.0.2 streamlit-1.54.0 tenacity-9.1.4 toml-0.10.2 tzdata-2025.3 watchdog-6.0.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 26.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install streamlit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addfb377",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
